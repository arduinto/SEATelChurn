{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Problem Overview\n",
    "In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition. So we need to analyse telecom industry data and predict high value customers who are at high risk of churn and identify main indicators of churn. In this project, you will analyse customer-level data of a leading telecom firm, build predictive models to identify customers at high risk of churn and identify the main indicators of churn.\n",
    "\n",
    "### Business objective\n",
    "The business objective is to predict the churn in the last (i.e. the ninth) month using the features/data from the first three months. To do this task well, understanding the typical customer behaviour during churn will be helpful.\n",
    "\n",
    "### Understanding Customer Behaviour During Churn\n",
    "Customers usually do not decide to switch to another competitor instantly, but rather over a period of time (this is especially applicable to high-value customers). In churn prediction, we assume that there are three phases of customer lifecycle :\n",
    "\n",
    "The ‘good’ phase: In this phase, the customer is happy with the service and behaves as usual.\n",
    "\n",
    "The ‘action’ phase: The customer experience starts to sore in this phase, for e.g. he/she gets a compelling offer from a competitor, faces unjust charges, becomes unhappy with service quality etc. In this phase, the customer usually shows different behaviour than the ‘good’ months. Also, it is crucial to identify high-churn-risk customers in this phase, since some corrective actions can be taken at this point (such as matching the competitor’s offer/improving the service quality etc.)\n",
    "\n",
    "The ‘churn’ phase: In this phase, the customer is said to have churned. You define churn based on this phase. Also, it is important to note that at the time of prediction (i.e. the action months), this data is not available to you for prediction. Thus, after tagging churn as 1/0 based on this phase, you discard all data corresponding to this phase.\n",
    "\n",
    "In this case, since you are working over a four-month window, the first two months are the ‘good’ phase, the third month is the ‘action’ phase, while the fourth month is the ‘churn’ phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About dataset:\n",
    "Dataset contains customer-level information for a span of four consecutive months - June, July, August and September. The months are encoded as 6, 7, 8 and 9, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZDZT2ZYYM7P7HSBKJGH48HX",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Import Libraries\n",
    "import sys,joblib\n",
    "import six\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "sys.modules['sklearn.externals.joblib'] = joblib\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\", font_scale = 0.65, rc={\"grid.linewidth\": 5})\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression,LassoCV,Lasso,Ridge,LogisticRegressionCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA,IncrementalPCA\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score,KFold,StratifiedKFold,RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,precision_score,recall_score\n",
    "from sklearn.metrics import precision_recall_curve,roc_auc_score,roc_curve\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler,ADASYN\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,QuantileTransformer\n",
    "from scipy.stats import skew\n",
    "from fancyimpute import IterativeImputer,KNN\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB,GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.feature_selection import RFE\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZE0GQGZG74DCVPCPSNVBJWH",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom = pd.read_csv('./telecom_churn_data.csv')\n",
    "telecom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZE0KZKV2W3PY2FG418S901M",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(telecom.shape)\n",
    "print('\\n')\n",
    "print(telecom.info(verbose=True, show_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZE1E9N4YPWV2PR1RGEKVZ3R",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary and checking outliers\n",
    "telecom.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZE1HWXHS6DY3QJFJ67BNCVK",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check percentage f null values present in dataset\n",
    "def calnullpercentage(df):\n",
    "    missing_num = df[df.columns].isna().sum().sort_values(ascending=False)\n",
    "    missing_perc = (df[df.columns].isna().sum()/len(df)*100).sort_values(ascending=False)\n",
    "    missing = pd.concat([missing_num, missing_perc], keys=['Total', 'Percentage'], axis=1)\n",
    "    missing = missing[missing['Percentage'] > 0]\n",
    "    # missing['Total'] = missing['Total'].apply(lambda x: f'{x:,}')\n",
    "    # missing['Percentage'] = missing['Percentage'].apply(lambda x: f'{x:.2f}%')\n",
    "    return missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZE1M8QGWZGCPKZR8H1VV4TG",
   "metadata": {},
   "outputs": [],
   "source": [
    "calnullpercentage(telecom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZGJP16WHT0HCZVC6WXX509W",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(calnullpercentage(telecom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 226 Columns, 166 have null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZGJR2KAKRF7KHAHE4HVXXWK",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.select_dtypes(include='object').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter High-Value Customers\n",
    "We need to predict churn only for the high-value customers. Define high-value customers as follows: Those who have recharged with an amount more than or equal to X, where X is the 70th percentile of the average recharge amount in the first two months (the good phase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZGK1KYGGR8BBQ2T23MHT3YM",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deriving new columns for total recharge amount data for 6 and 7th month\n",
    "telecom['tot_rech_amt_data_6'] = telecom['total_rech_data_6'] * telecom['av_rech_amt_data_6']\n",
    "telecom['tot_rech_amt_data_7'] = telecom['total_rech_data_7'] * telecom['av_rech_amt_data_7']\n",
    "\n",
    "# Deriving new columns for total amount spent during 6 and 7th month\n",
    "telecom['tot_amt_6'] = telecom[['total_rech_amt_6', 'tot_rech_amt_data_6']].sum(axis=1)\n",
    "telecom['tot_amt_7'] = telecom[['total_rech_amt_7', 'tot_rech_amt_data_7']].sum(axis=1)\n",
    "\n",
    "# First two months average\n",
    "telecom['avg_amt_6_7'] = telecom[['tot_amt_6', 'tot_amt_7']].mean(axis=1)\n",
    "\n",
    "# Filtering customers based on percentile havoong goodphase_avg more than or equal to cutoff of 70th percentile\n",
    "telecom = telecom.loc[(telecom['avg_amt_6_7'] >= np.percentile(telecom['avg_amt_6_7'], 70))]\n",
    "\n",
    "telecom.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have taken  recharge amountmore than or equal to X, where X is the 70th percentile of the average recharge amount in the first two months and getting 30k rows. If I usemore than(>)sign, will get 29.9k rows, but going with problem statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZGKD71TM1HD9H8534T640HD",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deriving new columns for total recharge amount data for 8 and 9th month\n",
    "telecom['tot_rech_amt_data_8'] = telecom['total_rech_data_8'] * telecom['av_rech_amt_data_8']\n",
    "telecom['tot_rech_amt_data_9'] = telecom['total_rech_data_9'] * telecom['av_rech_amt_data_9']\n",
    "\n",
    "# Deriving new columns for total amount spent during 8 and 9th month\n",
    "telecom['tot_amt_8'] = telecom[['total_rech_amt_8', 'tot_rech_amt_data_8']].sum(axis=1)\n",
    "telecom['tot_amt_9'] = telecom[['total_rech_amt_9', 'tot_rech_amt_data_9']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZH0ZHRFZ3457MSGXT4FYP21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding categorical columns where dtype is float but those columns are having 0 or 1 values only\n",
    "cats = []\n",
    "for col in telecom.columns:\n",
    "    if len(telecom[col].unique()) == 2 | 3:\n",
    "        cats.append(col)\n",
    "\n",
    "# Converting into categorical or object type\n",
    "telecom[cats] = telecom[cats].apply(lambda x: x.astype('object'))\n",
    "\"\"\"\n",
    "accessing column using np.r_\n",
    "`total_rech_num_6` to `total rech_num_9`\n",
    "`total_rech_data_6` to `total_rech_data_9`\n",
    "\"\"\"\n",
    "col_tmp = telecom.columns[np.r_[137:141, 161:165]]\n",
    "telecom[col_tmp] = telecom[col_tmp].apply(lambda x: x.astype('object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZH16ZKCDBTX1VHK9YH0MMW0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['tot_amt_8', 'total_rech_amt_8', 'tot_rech_amt_data_8', 'total_rech_data_8', 'av_rech_amt_data_8']\n",
    "plt.figure(figsize=(8,5))\n",
    "fig = sns.heatmap(telecom[x].corr(), annot=True, cmap='flare')\n",
    "plt.xticks(rotation=45, horizontalalignment='right')\n",
    "# fig.set_xticklabels(fig.get_xticklabels(), rotation=45, horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping Redundant columns, since we have already created derived features from them and derived features reflects the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZH1QMP8KC1G04QMEJ4FTTY6",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.drop(['tot_rech_amt_data_6', 'tot_rech_amt_data_7','tot_rech_amt_data_8', 'tot_rech_amt_data_9'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying CHURN CUSTOMERS\n",
    "Now tag the churned customers (churn=1, else 0) based on the fourth month as follows: Those who have not made any calls (either incoming or outgoing) AND have not used mobile internet even once in the churn phase. The attributes you need to use to tag churners are:\n",
    "\n",
    "* total_ic_mou_9\n",
    "* total_og_mou_9\n",
    "* vol_2g_mb_9\n",
    "* vol_3g_mb_9\n",
    "\n",
    "After tagging churners, remove all the attributes corresponding to the churn phase (all attributes having ‘ _9’, etc. in their names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZH6M0K2H4GKQMXRSNF9TFVS",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where summation of columns = 0 then churn = 1 else 0\n",
    "telecom['churn'] = np.where(telecom[['total_ic_mou_9', 'total_og_mou_9', 'vol_2g_mb_9', 'vol_3g_mb_9']].sum(axis=1) == 0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZHAKHZS36PJJSHNR9E1EWQV",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all features having '_9', etc. in their names\n",
    "telecom.drop(telecom.filter(regex='_9|sep', axis=1).columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZHBDAXT1HCVMTHBDMMA90MR",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(round(telecom['churn'].value_counts(normalize=True)*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximately 92% customers not churned and 8% customers got churned. Also, we can see class imbalance is there and we will deal with it later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each feature, it counts the values of that feature. If the most recurrent value of the feature is repeated almost in all the instances (**zeros / len(X) * 100 > 95**). Then it drops these features because their values are almost the same for all instances and will not help in learning process and those features are not useful in our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZHBS0ZNG2PMXXJ8EW10V538",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZHBSCA1TJ5EYE5J10C8TKHW",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redundant_features(df):\n",
    "    redundant = []\n",
    "    for i in df.columns:\n",
    "        counts = df[i].value_counts()\n",
    "        count_max = counts.iloc[0]\n",
    "        if count_max / len(df) * 100 > 95:\n",
    "            redundant.append(i)\n",
    "    redundant = list(redundant)\n",
    "    return redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZHBZJSSHSCEKR3MKYN3F9R3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before dropping Redundant features: ', telecom.shape)\n",
    "redundant_features = redundant_features(telecom)\n",
    "telecom = telecom.drop(redundant_features, axis=1)\n",
    "print('After dropping Redundant features: ', telecom.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to impute NaN values where %age of missing values > 40%, Reason for taking cutoff 40% is beacuse for these columns we can replace NaN with 0(for example, fb_user_7, not used facebook(NaN),av_rech_amt_data_8, not done recharge(NaN) similarly for other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZHCH6NDQZSJ1E4K7Z8080CC",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "# Function to impute NaN with 0\n",
    "Function to impute NaN values where %age of missing values > 40%,\n",
    "Reason for taking cutoff 40% is beacuse for these columns we can replace NaN with 0\n",
    "(for example, fb_user_7, not used facebook(NaN),av_rech_amt_data_8, not done recharge(NaN) similarly for other columns.\n",
    "\"\"\"\n",
    "\n",
    "def imputeNaN(df, col_name):\n",
    "    for col in col_name:\n",
    "        df[col].fillna(0, inplace=True)\n",
    "\n",
    "col_40 = calnullpercentage(telecom)[calnullpercentage(telecom)['Percentage'] > 40].index\n",
    "\n",
    "# Call Function\n",
    "imputeNaN(telecom, col_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZHDHEZ2XB991Y9D4D6GVY7W",
   "metadata": {},
   "outputs": [],
   "source": [
    "calnullpercentage(telecom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above missing value dataframe and value count == 0, large percentage of values are zero in missing value columns. I can impute most missing value column having NaN value with 0 if I assume that they have not use local incoming service, special outgoing service that is why these columns have NaN values. But this assumption doesn't helping much beacuse most values in these columns have 0 and it infers the same thing. So Imputing missing values for columns mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZKNSVQTFGAY54FEF74SQ6JD",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame((telecom[calnullpercentage(telecom).index] == 0).sum().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZKPB99XNAE77TV963VGKB9E",
   "metadata": {},
   "outputs": [],
   "source": [
    "imput_col = list(set(calnullpercentage(telecom).index) - set(('date_of_last_rech_6', 'date_of_last_rech_7', 'date_of_last_rech_8')))\n",
    "knn_imp = KNNImputer()\n",
    "telecom[imput_col] = knn_imp.fit_transform(telecom[imput_col])\n",
    "calnullpercentage(telecom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZRXXZDVATMJXQG0JRSGVS42",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.fillna(0, inplace=True)\n",
    "# Checking % of null values\n",
    "calnullpercentage(telecom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZRXYX7V4BT23CZ59HVY7Y50",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZRXZDF31CRMBBRWMHXP1E9H",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missing value percentage if any\n",
    "calnullpercentage(telecom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZRY036M98BV0VNHGCB61YTC",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZRY0XSA3QK7GM8SEEKVC7K7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Duplicate mobile number\n",
    "len(telecom['mobile_number'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZRY2Y0CHCB4ACEBY5EX0AWQ",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "telecom.drop(telecom['mobile_number'], inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZRAXQA0KCECCPM18F2NNSPH",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pygwalker as pyg\n",
    "# walker = pyg.walk(telecom, theme_key='vega', dark='light', kernel_computation=True, kanaries_api_key='ak-8ac65ba5e922aa75e5ce395e5042ed3f420d1c8bc6c193882a5c2a24e17105f3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01HZRBE9GA8CNW2RNQPMW03QJA",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom.to_csv('C:/There/Stuff/Py/Python/cleanTelecom.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
